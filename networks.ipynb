{"cells":[{"cell_type":"code","execution_count":null,"id":"7dd62512","metadata":{"id":"7dd62512","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713723912313,"user_tz":240,"elapsed":28088,"user":{"displayName":"Vivian Weng","userId":"16986109935608411488"}},"outputId":"1b1aadf1-0e4d-46be-fa46-f1ac8d7ca248"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import torch\n","\n","%run '/content/drive/MyDrive/Colab Notebooks/CPSC 490/model/net_utils.ipynb'"]},{"cell_type":"code","execution_count":null,"id":"7d5f6084","metadata":{"lines_to_next_cell":1,"id":"7d5f6084"},"outputs":[],"source":["class NeuralNetwork(torch.nn.Module):\n","    '''\n","    Neural network class of fully connected layers\n","\n","    Arg(s):\n","        n_input_feature : int\n","            number of input features\n","        n_output : int\n","            number of output classes\n","    '''\n","\n","    def __init__(self, n_input_feature, n_output):\n","        super(NeuralNetwork, self).__init__()\n","\n","        # Create your 6-layer neural network using fully connected layers with ReLU activations\n","        # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n","        # https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html\n","        # https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n","\n","        # TODO: Instantiate 5 fully connected layers and choose number of neurons i.e. 512\n","        self.fully_connected_layer1 = torch.nn.Linear(in_features=n_input_feature, out_features=512)\n","        self.fully_connected_layer2 = torch.nn.Linear(in_features=512, out_features=256)\n","        self.fully_connected_layer3 = torch.nn.Linear(in_features=256, out_features=128)\n","        self.fully_connected_layer4 = torch.nn.Linear(in_features=128, out_features=64)\n","        self.fully_connected_layer5 = torch.nn.Linear(in_features=64, out_features=32)\n","\n","        # TODO: Define output layer\n","        self.output = torch.nn.Linear(in_features=32, out_features=n_output)\n","        self.relu = torch.nn.ReLU()\n","\n","    def forward(self, x):\n","        '''\n","        Forward pass through the neural network\n","\n","        Arg(s):\n","            x : torch.Tensor[float32]\n","                tensor of N x d\n","        Returns:\n","            torch.Tensor[float32]\n","                tensor of n_output predicted class\n","        '''\n","\n","        # TODO: Implement forward function\n","        output_fc1 = self.relu(self.fully_connected_layer1(x))\n","        output_fc2 = self.relu(self.fully_connected_layer2(output_fc1))\n","        output_fc3 = self.relu(self.fully_connected_layer3(output_fc2))\n","        output_fc4 = self.relu(self.fully_connected_layer4(output_fc3))\n","        output_fc5 = self.relu(self.fully_connected_layer5(output_fc4))\n","\n","        output_logits = self.output(output_fc5)\n","\n","        return output_logits"]},{"cell_type":"code","execution_count":null,"id":"26ea34d0","metadata":{"lines_to_next_cell":1,"id":"26ea34d0"},"outputs":[],"source":["class ResNet18Encoder(torch.nn.Module):\n","    '''\n","    ResNet18 encoder with skip connections\n","\n","    Arg(s):\n","        input_channels : int\n","            number of channels in input data\n","        n_filters : list\n","            number of filters to use for each block\n","        weight_initializer : str\n","            kaiming_normal, kaiming_uniform, xavier_normal, xavier_uniform\n","        activation_func : func\n","            activation function after convolution\n","        use_batch_norm : bool\n","            if set, then applied batch normalization\n","        use_instance_norm : bool\n","            if set, then applied instance normalization\n","    '''\n","\n","    def __init__(self,\n","                 input_channels=3,\n","                 n_filters=[64, 64, 128, 256, 512],\n","                 weight_initializer='kaiming_uniform',\n","                 activation_func='leaky_relu',\n","                 use_batch_norm=False,\n","                 use_instance_norm=False):\n","        super(ResNet18Encoder, self).__init__()\n","\n","        assert len(n_filters) == 5\n","\n","        n_blocks = [2, 2, 2, 2]\n","        resnet_block = ResNetBlock\n","\n","        activation_finc = activation_function(activation_func)\n","\n","        for n in range(len(n_filters) - len(n_blocks) - 1):\n","            n_blocks = n_blocks + [n_blocks[-1]]\n","\n","\n","        assert len(n_filters) == len(n_blocks) + 1\n","\n","        # Keep track on current block\n","        block_idx = 0\n","        filter_idx = 0\n","\n","        activation_func = activation_function(activation_func)\n","\n","        # TODO: Implement ResNet encoder using ResNeBlock from net_utils.py\n","        # Based on https://arxiv.org/abs/1512.03385\n","\n","        self.model = []\n","        x = Conv2d(in_channels=input_channels,\n","                  out_channels=n_filters[filter_idx],\n","                  kernel_size=7,\n","                  stride=2,\n","                  weight_initializer=weight_initializer,\n","                  activation_func=activation_func,\n","                  use_batch_norm=use_batch_norm,\n","                  use_instance_norm=use_instance_norm)\n","        self.model.append(x)\n","        x = torch.nn.MaxPool2d(kernel_size=3, stride=2)\n","        self.model.append(x)\n","        filter_idx += 1\n","\n","        for layer in range(0, len(n_blocks)):\n","            for block in range(0, n_blocks[layer]):\n","                if block == 0 and layer != 0:\n","                    stride = 2\n","                else:\n","                    stride = 1\n","                if block == 0:\n","                  x = resnet_block(in_channels=n_filters[filter_idx-1],\n","                                    out_channels=n_filters[filter_idx-1],\n","                                    stride = stride,\n","                                    weight_initializer=weight_initializer,\n","                                    activation_func=activation_func,\n","                                    use_batch_norm=use_batch_norm,\n","                                    use_instance_norm=use_instance_norm)\n","                  self.model.append(x)\n","                else:\n","                  x = resnet_block(in_channels=n_filters[filter_idx-1],\n","                                    out_channels=n_filters[filter_idx],\n","                                    stride = stride,\n","                                    weight_initializer=weight_initializer,\n","                                    activation_func=activation_func,\n","                                    use_batch_norm=use_batch_norm,\n","                                    use_instance_norm=use_instance_norm)\n","                  self.model.append(x)\n","            filter_idx += 1\n","            block_idx += 1\n","\n","        self.model = torch.nn.Sequential(*self.model)\n","\n","\n","\n","    def forward(self, x):\n","        '''\n","        Forward input x through a ResNet encoder\n","\n","        Arg(s):\n","            x : torch.Tensor[float32]\n","                N x C x H x W input tensor\n","        Returns:\n","            torch.Tensor[float32] : N x K x h x w output tensor\n","            list[torch.Tensor[float32]] : list of intermediate feature maps used for skip connections\n","        '''\n","        layers = [x]\n","\n","        # TODO: Implement forward function\n","\n","        layer_count = 0\n","        for conv in self.model:\n","            layer_count += 1\n","\n","            layers.append(conv(layers[-1]))\n","\n","        return layers[-1], layers[1:-2]"]},{"cell_type":"code","execution_count":null,"id":"a0156f0a","metadata":{"id":"a0156f0a"},"outputs":[],"source":["class VGGNet11Encoder(torch.nn.Module):\n","    '''\n","    VGGNet encoder with skip connections\n","\n","    Arg(s):\n","        input_channels : int\n","            number of channels in input data\n","        n_filters : list\n","            number of filters to use for each block\n","        weight_initializer : str\n","            kaiming_normal, kaiming_uniform, xavier_normal, xavier_uniform\n","        activation_func : func\n","            activation function after convolution\n","        use_batch_norm : bool\n","            if set, then applied batch normalization\n","        use_instance_norm : bool\n","            if set, then applied instance normalization\n","    '''\n","\n","    def __init__(self,\n","                 input_channels=512,\n","                 n_filters=[32, 64, 128, 256, 256],\n","                 weight_initializer='kaiming_uniform',\n","                 activation_func='leaky_relu',\n","                 use_batch_norm=False,\n","                 use_instance_norm=False):\n","        super(VGGNet11Encoder, self).__init__()\n","\n","        activation_func = activation_function(activation_func)\n","\n","        # TODO: Implement VGGNet encoder using VGGNetBlock from net_utils.py\n","        # Based on https://arxiv.org/pdf/1409.1556.pdf\n","\n","        n_convolutions = [1, 1, 2, 2, 2]  # VGG11\n","        stride = 1\n","\n","        assert len(n_convolutions) == len(n_filters)\n","        block_num = 0\n","\n","        in_channels, out_channels = [input_channels, n_filters[block_num]]\n","\n","        self.conv1 = Conv2d(\n","            in_channels,\n","            out_channels,\n","            kernel_size=3,\n","            stride=stride,\n","            weight_initializer=weight_initializer,\n","            activation_func=activation_func,\n","            use_batch_norm=use_batch_norm,\n","            use_instance_norm=use_instance_norm\n","        )\n","\n","        block_num = 1\n","        in_channels, out_channels = [n_filters[block_num - 1], n_filters[block_num]]\n","\n","        self.conv2 = VGGNetBlock(\n","            in_channels,\n","            out_channels,\n","            n_convolution=n_convolutions[block_num],\n","            stride=2,\n","            weight_initializer=weight_initializer,\n","            activation_func=activation_func,\n","            use_batch_norm=use_batch_norm,\n","            use_instance_norm=use_instance_norm)\n","\n","        block_num = 2\n","        in_channels, out_channels = [n_filters[block_num - 1], n_filters[block_num]]\n","\n","        self.conv3 = VGGNetBlock(\n","            in_channels,\n","            out_channels,\n","            n_convolution=n_convolutions[block_num],\n","            stride=2,\n","            weight_initializer=weight_initializer,\n","            activation_func=activation_func,\n","            use_batch_norm=use_batch_norm,\n","            use_instance_norm=use_instance_norm)\n","\n","        block_num = 3\n","        in_channels, out_channels = [n_filters[block_num - 1], n_filters[block_num]]\n","\n","        self.conv4 = VGGNetBlock(\n","            in_channels,\n","            out_channels,\n","            n_convolution=n_convolutions[block_num],\n","            stride=2,\n","            weight_initializer=weight_initializer,\n","            activation_func=activation_func,\n","            use_batch_norm=use_batch_norm,\n","            use_instance_norm=use_instance_norm)\n","\n","        block_num = 4\n","        in_channels, out_channels = [n_filters[block_num - 1], n_filters[block_num]]\n","\n","        self.conv5 = VGGNetBlock(\n","            in_channels,\n","            out_channels,\n","            n_convolution=n_convolutions[block_num],\n","            stride=2,\n","            weight_initializer=weight_initializer,\n","            activation_func=activation_func,\n","            use_batch_norm=use_batch_norm,\n","            use_instance_norm=use_instance_norm)\n","\n","        self.max_pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","    def forward(self, x):\n","        '''\n","        Forward input x through a VGGNet encoder\n","\n","        Arg(s):\n","            x : torch.Tensor[float32]\n","                N x C x H x W input tensor\n","        Returns:\n","            torch.Tensor[float32] : N x K x h x w output tensor\n","            list[torch.Tensor[float32]] : list of intermediate feature maps used for skip connections\n","        '''\n","\n","        layers = [x]\n","\n","        # TODO: Implement forward function\n","        layers.append(self.conv1(layers[-1]))\n","        layers.append(self.conv2(layers[-1]))\n","        layers.append(self.conv3(layers[-1]))\n","        layers.append(self.conv4(layers[-1]))\n","        layers.append(self.conv5(layers[-1]))\n","        layers.append(self.max_pool(layers[-1]))\n","\n","        # Return latent and intermediate features\n","        return layers[-1], layers[1:-1]"]}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}