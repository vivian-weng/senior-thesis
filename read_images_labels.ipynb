{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN9fxrIjY7jT9tywWgbllLp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import cv2\n","from PIL import Image\n","import torch\n","from torchvision import transforms\n","from torch.utils.data import DataLoader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B1mCepWjXbxO","executionInfo":{"status":"ok","timestamp":1713832347325,"user_tz":240,"elapsed":14167,"user":{"displayName":"Vivian Weng","userId":"16986109935608411488"}},"outputId":"1e2af76b-e7f7-4dea-8e46-e6a0728548bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"8LHzcY0GShDc"}},{"cell_type":"code","source":["# Initialize stroke folder paths\n","stroke_folders = [\"BK1\", \"BR1\", \"FL1\", \"FR1\", \"BK2\", \"BR2\", \"FL2\", \"FR2\"]\n","folder_path = \"/content/drive/MyDrive/Colab Notebooks/CPSC 490/Images/\"\n","\n","# Initialize array for image paths and data array\n","image_paths = []\n","data_array = []\n","big_df = pd.DataFrame()\n","# loop through folders\n","for folder in stroke_folders:\n","  os.chdir(folder_path + folder)\n","  segment_folders = [x for x in os.listdir() if \"Segment\" in x]\n","\n","  stroke_data_array = []\n","  # loop through segments to read all excel files\n","  for segment in segment_folders:\n","    labels_file = folder_path + folder + \"/\" + segment + \"/labels.xlsx\"\n","    # read excel file and append image path of frame to image pathslist\n","    df = pd.read_excel(labels_file, header=None)\n","    image_paths.extend([folder_path + folder + \"/\" + segment + \"/\"] * 30)\n","    # add spreadsheet labels to big dataframe\n","    big_df = pd.concat([big_df, df], ignore_index=True)\n"],"metadata":{"id":"OBTklOhnXi__"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define column names\n","column_names = ['image', 'stroke', 'completion', 'vid_segment']\n","big_df.columns = column_names\n","\n","# loop through columns of big dataframe and add to data array\n","for col in column_names:\n","    data_array.append(big_df[col])\n","\n","# use numpy to convert data array to np array\n","data_array = np.array(data_array)"],"metadata":{"id":"Fs7XpmFHR0Eg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_paths = [str(x) + str(y) for x, y in zip(image_paths, data_array[0])]"],"metadata":{"id":"eYUMaBuKve0Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class StrokeTypeTrainingDataset(torch.utils.data.Dataset):\n","    '''\n","    Dataset for fetching:\n","        (1) image\n","        (2) label (integer 0-3)\n","\n","    Arg(s):\n","        image_paths : list[str]\n","            paths to image\n","        labels : list[int]\n","            labels containing stroke types\n","            0: butterfly\n","            1: backstroke\n","            2: breaststroke\n","            3: freestyle\n","        resize_shape : tuple[int]\n","            shape (height, width) to resize inputs\n","    '''\n","\n","    def __init__(self,\n","                 image_paths,\n","                 labels,\n","                 resize_shape):\n","\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.resize_shape = resize_shape\n","\n","    def __getitem__(self, index):\n","        # Load image\n","        image_path = self.image_paths[index]\n","        image = Image.open(image_path).convert(\"RGB\")\n","\n","        # Convert from PIL image to numpy array\n","        image = np.array(image)\n","\n","        # Load label\n","        label = np.array(self.labels[index])\n","\n","        # Resize image to resize_shape\n","        image = cv2.resize(\n","              image,\n","              [self.resize_shape[1], self.resize_shape[0]],\n","              interpolation = cv2.INTER_LINEAR)\n","\n","        image = np.transpose(image, [2, 0, 1])\n","\n","        # Convert to float32\n","        image = image.astype(np.float32)\n","        label = label.astype(np.int64)\n","\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.image_paths)"],"metadata":{"id":"ad_6_BIiK1Vo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class StrokeCompletionTrainingDataset(torch.utils.data.Dataset):\n","    '''\n","    Dataset for fetching:\n","        (1) image\n","        (2) label (integer 0-1)\n","\n","    Arg(s):\n","        image_paths : list[str]\n","            paths to image\n","        labels : list[int]\n","            labels containing stroke completion\n","            0: stroke not complete\n","            1: stroke complete\n","        resize_shape : tuple[int]\n","            shape (height, width) to resize inputs\n","    '''\n","\n","    def __init__(self,\n","                 image_paths,\n","                 labels,\n","                 resize_shape):\n","\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.resize_shape = resize_shape\n","\n","    def __getitem__(self, index):\n","        # Load image\n","        image_path = self.image_paths[index]\n","        image = Image.open(image_path).convert(\"RGB\")\n","\n","        # Convert from PIL image to numpy array\n","        image = np.array(image)\n","\n","        # Load label\n","        label = np.array(self.labels[index])\n","\n","        # Resize image to resize_shape\n","        image = cv2.resize(\n","              image,\n","              [self.resize_shape[1], self.resize_shape[0]],\n","              interpolation = cv2.INTER_LINEAR)\n","\n","        image = np.transpose(image, [2, 0, 1])\n","\n","        # Convert to float32\n","        image = image.astype(np.float32)\n","        label = label.astype(np.int64)\n","\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.image_paths)"],"metadata":{"id":"ZJcwaLCfMI3m","colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"status":"error","timestamp":1714352748836,"user_tz":240,"elapsed":196,"user":{"displayName":"Vivian Weng","userId":"16986109935608411488"}},"outputId":"dbd6961e-74e2-40be-991a-a77e49b13a84"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'torch' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-27e44f243663>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mStrokeCompletionTrainingDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     '''\n\u001b[1;32m      3\u001b[0m     \u001b[0mDataset\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetching\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minteger\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}]},{"cell_type":"code","source":["class VideoSegmentTrainingDataset(torch.utils.data.Dataset):\n","    '''\n","    Dataset for fetching:\n","        (1) image\n","        (2) label (integer 0-4)\n","\n","    Arg(s):\n","        image_paths : list[str]\n","            paths to image\n","        labels : list[int]\n","            labels containing video segment\n","            0: not swimming\n","            1: underwater\n","            2: swimming\n","            3: turn\n","        resize_shape : tuple[int]\n","            shape (height, width) to resize inputs\n","    '''\n","\n","    def __init__(self,\n","                 image_paths,\n","                 labels,\n","                 resize_shape):\n","\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.resize_shape = resize_shape\n","\n","    def __getitem__(self, index):\n","        # Load image\n","        image_path = self.image_paths[index]\n","        image = Image.open(image_path).convert(\"RGB\")\n","\n","        # Convert from PIL image to numpy array\n","        image = np.array(image)\n","\n","        # Load label\n","        label = np.array(self.labels[index])\n","\n","        # Resize image to resize_shape\n","        image = cv2.resize(\n","              image,\n","              [self.resize_shape[1], self.resize_shape[0]],\n","              interpolation = cv2.INTER_LINEAR)\n","\n","        image = np.transpose(image, [2, 0, 1])\n","\n","        # Convert to float32\n","        image = image.astype(np.float32)\n","        label = label.astype(np.int64)\n","\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.image_paths)"],"metadata":{"id":"DhpDgnf2MJtT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define training split\n","train_split_size = int(0.80 * len(image_paths))\n","\n","# Define image paths and labels\n","image_paths = np.array(image_paths)\n","labels_stroke = np.array(data_array[1])\n","labels_completion = np.array(data_array[2])\n","labels_vid_seg = np.array(data_array[3])\n","\n","# Divide images into training and testing images\n","train_image_paths = image_paths[0: train_split_size]\n","test_image_paths = image_paths[train_split_size:]\n","\n","# Divide labels into training and testing labels\n","train_labels_stroke = labels_stroke[0: train_split_size]\n","train_labels_completion = labels_completion[0: train_split_size]\n","# train_labels_vid_seg = labels_vid_seg[0: train_split_size]\n","\n","test_labels_stroke = labels_stroke[train_split_size:]\n","test_labels_completion = labels_completion[train_split_size:]\n","# test_labels_vid_seg = labels_vid_seg[train_split_size:]\n","\n","# Define datasets for each set of training/testing images and labels\n","training_stroke_dataset = StrokeTypeTrainingDataset(image_paths=train_image_paths, labels=train_labels_stroke, resize_shape=(256,256))\n","training_completion_dataset = StrokeCompletionTrainingDataset(image_paths=train_image_paths, labels=train_labels_completion, resize_shape=(256,256))\n","# training_vid_seg_dataset = VideoSegmentTrainingDataset(image_paths=train_image_paths, labels=train_labels_vid_seg, resize_shape=(256,256))\n","\n","testing_stroke_dataset = StrokeTypeTrainingDataset(image_paths=test_image_paths, labels=test_labels_stroke, resize_shape=(256,256))\n","testing_completion_dataset = StrokeTypeTrainingDataset(image_paths=test_image_paths, labels=test_labels_completion, resize_shape=(256,256))\n","\n","# Define batch size\n","batch_size = 25\n","\n","# Define dataloaders for each training and testing dataset\n","training_stroke_dataloader = DataLoader(training_stroke_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2)\n","testing_stroke_dataloader = DataLoader(testing_stroke_dataset, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=1)\n","\n","training_completion_dataloader = DataLoader(training_completion_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2)\n","testing_completion_dataloader = DataLoader(testing_completion_dataset, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=1)"],"metadata":{"id":"JRGfJ1FTS3Of"},"execution_count":null,"outputs":[]}]}